{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e98213d-13f4-48d4-9345-28108a3d530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator,os\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv\n",
    "from contextlib import ExitStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "294f2050-7d0c-4610-8aca-271f5150bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key=os.getenv('OPENAI_API_KEY')\n",
    "tavily_api_key = os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da1cb491-0cae-419b-8290-d9030e86b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daf36f6d-ac73-425c-8eb1-c3bbebe78b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "stack = ExitStack()\n",
    "memory = stack.enter_context(SqliteSaver.from_conn_string(\":memory:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cdb131b-061f-431b-9c6d-3d78e0576aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "def reduce_messages(left: list[AnyMessage], right: list[AnyMessage]) -> list[AnyMessage]:\n",
    "    for message in right:\n",
    "        if not message.id:\n",
    "            message.id = str(uuid4())\n",
    "    merged = left.copy()\n",
    "    for message in right:\n",
    "        for i, existing in enumerate(merged):\n",
    "            if existing.id == message.id:\n",
    "                merged[i] = message\n",
    "                break\n",
    "        else:\n",
    "            merged.append(message)\n",
    "    return merged\n",
    "class AgentState(TypedDict):\n",
    "    messages : Annotated[list[AnyMessage] , reduce_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e6f9a4a-adc7-4abe-b6b0-186724f9cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self,model,tools,system,checkpointer):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node('llm',self.call_llm)\n",
    "        graph.add_node('action',self.take_action)\n",
    "        graph.add_conditional_edges('llm',self.exist_action,{True:'action',False:END})\n",
    "        graph.add_edge('action','llm')\n",
    "        graph.set_entry_point('llm')\n",
    "        self.graph = graph.compile(\n",
    "            checkpointer=checkpointer,\n",
    "            interrupt_before = ['action']\n",
    "        )\n",
    "        self.tools = {t.name : t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_llm(self, state : AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system :\n",
    "            messages = [SystemMessage(content = self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages' : [message]}\n",
    "\n",
    "    def take_action(self , state : AgentState):\n",
    "        tool_calls = state ['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling Action: {t}\")\n",
    "            if not t['name'] in self.tools:\n",
    "                print(\"\\n .....bad tool name .....\")\n",
    "                result = \"bad tool name , retry\"\n",
    "            else:\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to model !!\")\n",
    "        return {'messages' : results}\n",
    "\n",
    "    def exist_action(self,state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64b08e8f-5ac7-4c54-ba2e-b1c25b1717e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77c45843-856f-44f4-adac-a823db6aa8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model = \"gpt-3.5-turbo\")\n",
    "abot = Agent(model,[tool],system = prompt,checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6729205b-f2a5-463d-872b-6b5d096b18c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling Action: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_tcimQdoq1THBWWHMQGucgBTr', 'type': 'tool_call'}\n",
      "Back to model !!\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "  for v in event.values():\n",
    "      print(v)\n",
    "while(abot.graph.get_state(thread).next):\n",
    "    print('\\n',abot.graph.get_state(thread),'\\n')\n",
    "    _input = input(\"proceed?(y/n)\")\n",
    "    if _input != 'y':\n",
    "        print(\"aborting\")\n",
    "        break\n",
    "    for event in abot.graph.stream(None, thread):\n",
    "        for v in event.values():\n",
    "            print(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3277fe7",
   "metadata": {},
   "source": [
    "----------Streaning messages ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231e7fa-26c0-4388-ad92-aa42147d690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(\"Whats the weather in LA?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18bf7f1f-9859-4179-baa1-1ba500d9fd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling Action: {'name': 'tavily_search_results_json', 'args': {'query': '2024 Super Bowl winner'}, 'id': 'call_ggvc4r2vn3PyEsxIqQUMgLpx', 'type': 'tool_call'}\n",
      "Back to model !!\n",
      "Calling Action: {'name': 'tavily_search_results_json', 'args': {'query': 'Kansas City Chiefs headquarters location'}, 'id': 'call_cgdbTxnCxeLc9Uq38lJdgvmt', 'type': 'tool_call'}\n",
      "Calling Action: {'name': 'tavily_search_results_json', 'args': {'query': 'GDP of Missouri 2024'}, 'id': 'call_VZJtH8mt0P6iTAijAIWqTWhH', 'type': 'tool_call'}\n",
      "Back to model !!\n"
     ]
    }
   ],
   "source": [
    "abot.graph.get_state(thread)\n",
    "current_state = abot.graph.get_state(thread)\n",
    "current_state.values['messages'][-1].tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a3f5d2",
   "metadata": {},
   "source": [
    "------------update state message,this ill override the valuue in the state ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f85880ca-b6a4-46fd-afe1-262cd2b8609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Who won the Super Bowl in 2024?**\n",
      "\n",
      "   The Kansas City Chiefs won the Super Bowl in 2024, defeating the San Francisco 49ers 25-22 in overtime.\n",
      "\n",
      "2. **In what state is the winning team's headquarters located?**\n",
      "\n",
      "   The Kansas City Chiefs' headquarters is located in Missouri.\n",
      "\n",
      "3. **What is the GDP of that state?**\n",
      "\n",
      "   The GDP of Missouri as of 2024 is approximately $34.3 trillion.\n"
     ]
    }
   ],
   "source": [
    "_id = current_state.values['messages'][-1].tool_calls[0]['id']\n",
    "current_state.values['messages'][-1].tool_calls = [\n",
    "    {'name': 'tavily_search_results_json',\n",
    "  'args': {'query': 'weather in Louisiana'},\n",
    "  'id': _id,\n",
    "  'type': 'tool_call'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91904976-5209-4b19-a3ed-e87fbed57639",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.update_state(thread,current_state.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1883a3f",
   "metadata": {},
   "source": [
    "------After updating stream the message without interrup(by passing none as arg)--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.get_state(thread)\n",
    "for event in abot.graph.stream(None,thread):\n",
    "    for v in event.values():\n",
    "        print(v)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702a214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "for state in abot.graph.get_state_history(thread):\n",
    "    print(state,'\\n..........\\n')\n",
    "    states.append(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ffd76d",
   "metadata": {},
   "source": [
    "-------- Time travelling to tird last state ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d132b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay = states[-3]\n",
    "for event in abot.graph.stream(None, to_replay.config):\n",
    "    for k, v in event.items():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e01e2",
   "metadata": {},
   "source": [
    "--------update that state value ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eef83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = to_replay.values['messages'][-1].tool_calls[0]['id']\n",
    "to_replay.values['messages'][-1].tool_calls = [\n",
    "    {'name': 'tavily_search_results_json',\n",
    "  'args': {'query': 'weather in Los Angeles,accuweather'},\n",
    "  'id': _id,\n",
    "  'type': 'tool_call'}]\n",
    "branch_state=abot.graph.update_state(to_replay.config,to_replay.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a18a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None,branch_state):\n",
    "    for k, v in event.items():\n",
    "        print(v)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d2ece1",
   "metadata": {},
   "source": [
    "---------- update the tome travelled state ,this upfate will add new message value rather than updationg existing one -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = to_replay.values['messages'][-1].tool_calls[0]['id']\n",
    "state_update= {\"messages\" : [ToolMessage(\n",
    "    tool_call_id = _id,\n",
    "    name = \"tavily_search_results_json\",\n",
    "    content = \"54 degree celcius\"\n",
    ")]}\n",
    "branch_and_add = abot.graph.update_state(\n",
    "    to_replay.config,\n",
    "    state_update,\n",
    "    as_node = 'action'\n",
    ")\n",
    "for event in abot.graph.stream(None,branch_and_add):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
