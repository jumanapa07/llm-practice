{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e98213d-13f4-48d4-9345-28108a3d530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator,os\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "294f2050-7d0c-4610-8aca-271f5150bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key=os.getenv('OPENAI_API_KEY')\n",
    "tavily_api_key = os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da1cb491-0cae-419b-8290-d9030e86b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daf36f6d-ac73-425c-8eb1-c3bbebe78b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n"
     ]
    }
   ],
   "source": [
    "print(type(tool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cdb131b-061f-431b-9c6d-3d78e0576aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages : Annotated[list[AnyMessage] , operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e6f9a4a-adc7-4abe-b6b0-186724f9cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self,model,tools,system):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node('llm',self.call_llm)\n",
    "        graph.add_node('action',self.take_action)\n",
    "        graph.add_conditional_edges('llm',self.exist_action,{True:'action',False:END})\n",
    "        graph.add_edge('action','llm')\n",
    "        graph.set_entry_point('llm')\n",
    "        self.graph = graph.compile()\n",
    "        self.tools = {t.name : t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_llm(self, state : AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system :\n",
    "            messages = [SystemMessage(content = self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages' : [message]}\n",
    "\n",
    "    def take_action(self , state : AgentState):\n",
    "        tool_calls = state ['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling Action: {t}\")\n",
    "            if not t['name'] in self.tools:\n",
    "                print(\"\\n .....bad tool name .....\")\n",
    "                result = \"bad tool name , retry\"\n",
    "            else:\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to model !!\")\n",
    "        return {'messages' : results}\n",
    "\n",
    "    def exist_action(self,state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64b08e8f-5ac7-4c54-ba2e-b1c25b1717e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77c45843-856f-44f4-adac-a823db6aa8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model = \"gpt-3.5-turbo\")\n",
    "bot = Agent(model,[tool],system = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6729205b-f2a5-463d-872b-6b5d096b18c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling Action: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_tcimQdoq1THBWWHMQGucgBTr', 'type': 'tool_call'}\n",
      "Back to model !!\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
    "result = bot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231e7fa-26c0-4388-ad92-aa42147d690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18bf7f1f-9859-4179-baa1-1ba500d9fd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling Action: {'name': 'tavily_search_results_json', 'args': {'query': '2024 Super Bowl winner'}, 'id': 'call_ggvc4r2vn3PyEsxIqQUMgLpx', 'type': 'tool_call'}\n",
      "Back to model !!\n",
      "Calling Action: {'name': 'tavily_search_results_json', 'args': {'query': 'Kansas City Chiefs headquarters location'}, 'id': 'call_cgdbTxnCxeLc9Uq38lJdgvmt', 'type': 'tool_call'}\n",
      "Calling Action: {'name': 'tavily_search_results_json', 'args': {'query': 'GDP of Missouri 2024'}, 'id': 'call_VZJtH8mt0P6iTAijAIWqTWhH', 'type': 'tool_call'}\n",
      "Back to model !!\n"
     ]
    }
   ],
   "source": [
    "query = \"Who won the super bowl in 2024? In what state is the winning team headquarters located? \\\n",
    "What is the GDP of that state? Answer each question.\" \n",
    "messages = [HumanMessage(content=query)]\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")  \n",
    "abot = Agent(model, [tool], system=prompt)\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f85880ca-b6a4-46fd-afe1-262cd2b8609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Who won the Super Bowl in 2024?**\n",
      "\n",
      "   The Kansas City Chiefs won the Super Bowl in 2024, defeating the San Francisco 49ers 25-22 in overtime.\n",
      "\n",
      "2. **In what state is the winning team's headquarters located?**\n",
      "\n",
      "   The Kansas City Chiefs' headquarters is located in Missouri.\n",
      "\n",
      "3. **What is the GDP of that state?**\n",
      "\n",
      "   The GDP of Missouri as of 2024 is approximately $34.3 trillion.\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91904976-5209-4b19-a3ed-e87fbed57639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
